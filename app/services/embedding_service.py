"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç sentence-transformers –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Ç–µ–∫—Å—Ç–∞.
"""
import os
from typing import List, Optional
from sentence_transformers import SentenceTransformer
import torch
import logging
from app.utils.logger import get_logger, LogLevel

logger = get_logger()

class EmbeddingService:
    _instance = None
    _model = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(EmbeddingService, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if self._model is None:
            self._initialize_model()
    
    def _initialize_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤."""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å paraphrase-multilingual-mpnet-base-v2 –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
            model_name = "paraphrase-multilingual-mpnet-base-v2"
            logger.log(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name}...", LogLevel.INFO)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ CUDA
            device = "cuda" if torch.cuda.is_available() else "cpu"
            logger.log(f"üñ•Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}", LogLevel.INFO)
            
            self._model = SentenceTransformer(model_name, device=device)
            logger.log("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞", LogLevel.INFO)
            
        except Exception as e:
            logger.log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}", LogLevel.ERROR)
            raise
    
    def get_embedding(self, text: str) -> List[float]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞.
        
        Args:
            text: –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç
            
        Returns:
            List[float]: –í–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–∏
            if self._model is None:
                self._initialize_model()
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
            embedding = self._model.encode(text, convert_to_tensor=False)
            
            return embedding.tolist()
            
        except Exception as e:
            logger.log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {str(e)}", LogLevel.ERROR)
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return [0.0] * 384
    
    async def get_embedding_async(self, text: str) -> List[float]:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞.
        
        Args:
            text: –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç
            
        Returns:
            List[float]: –í–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        """
        return self.get_embedding(text)  # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±–µ—Ä—Ç–∫–µ
    
    def get_batch_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤.
        
        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤
            
        Returns:
            List[List[float]]: –°–ø–∏—Å–æ–∫ –≤–µ–∫—Ç–æ—Ä–æ–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """
        try:
            if self._model is None:
                self._initialize_model()
            
            embeddings = self._model.encode(texts, convert_to_tensor=False)
            return embeddings.tolist()
            
        except Exception as e:
            logger.log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–∞–∫–µ—Ç–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {str(e)}", LogLevel.ERROR)
            return [[0.0] * 384] * len(texts) 