import logging
from typing import Dict, Any, List
from app.handlers.es_law_search import search_law_chunks
from app.handlers.web_search import WebSearchHandler
import asyncio
import time
import re
import chardet
from app.handlers.web_search import run_multiple_searches
from app.services.query_optimizer import QueryOptimizer
from app.services.tavily_service import TavilyService
import json
import os
import hashlib
from app.handlers.es_law_search import search_law_chunks_multi

def ensure_correct_encoding(text: str) -> str:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ç–µ–∫—Å—Ç–∞, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è UTF-8.
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        
    Returns:
        str: –¢–µ–∫—Å—Ç –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–µ UTF-8
    """
    if not text:
        return ""

    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —É–∂–µ –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏
    if isinstance(text, str):
        try:
            # –ü—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –∫–∏—Ä–∏–ª–ª–∏—Ü—É –≤ URL-–∫–æ–¥–∏—Ä–æ–≤–∫–µ
            text = re.sub(r'%D0%[89AB][0-9A-F]%D0%[89AB][0-9A-F]', 
                         lambda m: bytes.fromhex(m.group(0).replace('%', '')).decode('utf-8'), 
                         text)
            text = re.sub(r'%D0%[89AB][0-9A-F]', 
                         lambda m: bytes.fromhex(m.group(0).replace('%', '')).decode('utf-8'), 
                         text)
            
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
            replacements = {
                '√ê¬∞': '–∞', '√ê¬±': '–±', '√ê¬≤': '–≤', '√ê¬≥': '–≥', '√ê¬¥': '–¥',
                '√ê¬µ': '–µ', '√ë': '—ë', '√ê¬∂': '–∂', '√ê¬∑': '–∑', '√ê¬∏': '–∏',
                '√ê¬π': '–π', '√ê¬∫': '–∫', '√ê¬ª': '–ª', '√ê¬º': '–º', '√ê¬Ω': '–Ω',
                '√ê¬æ': '–æ', '√ê¬ø': '–ø', '√ë‚Ç¨': '—Ä', '√ë': '—Å', '√ë‚Äö': '—Ç',
                '√ë∆í': '—É', '√ë‚Äû': '—Ñ', '√ë‚Ä¶': '—Ö', '√ë‚Ä†': '—Ü', '√ë‚Ä°': '—á',
                '√ëÀÜ': '—à', '√ë‚Ä∞': '—â', '√ë≈†': '—ä', '√ë‚Äπ': '—ã', '√ë≈í': '—å',
                '√ë': '—ç', '√ë≈æ': '—é', '√ë': '—è'
            }
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—Å–µ –∑–∞–º–µ–Ω—ã
            for wrong, correct in replacements.items():
                text = text.replace(wrong, correct)
            
            # –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ bytes –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
            text = text.encode('utf-8', errors='ignore').decode('utf-8')
            
            # –£–¥–∞–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x9F]', '', text)
            text = re.sub(r'\s+', ' ', text)
            
            return text.strip()
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏: {e}")
            return text
            
    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –≤ bytes
    if isinstance(text, bytes):
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
            detected = chardet.detect(text)
            if detected and detected['encoding']:
                # –ü—Ä–æ–±—É–µ–º –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
                return text.decode(detected['encoding'], errors='ignore')
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ bytes: {e}")
            pass
            
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É, –ø—Ä–æ–±—É–µ–º UTF-8
        try:
            return text.decode('utf-8', errors='ignore')
        except UnicodeError:
            # –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º Latin-1
            return text.decode('latin1', errors='ignore')
            
    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –¥—Ä—É–≥–æ–≥–æ —Ç–∏–ø–∞, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
    return str(text)

async def run_parallel_search(query: str) -> Dict[str, Any]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö: ElasticSearch –∏ Tavily (–ø–æ –¥–≤—É–º —É—Ç–æ—á–Ω—ë–Ω–Ω—ã–º –∑–∞–ø—Ä–æ—Å–∞–º).
    –í–∫–ª—é—á–∞–µ—Ç –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ —É–ª—É—á—à–µ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫.
    –¢–µ–ø–µ—Ä—å: —Å–Ω–∞—á–∞–ª–∞ –∂–¥–µ—Ç —É—Ç–æ—á–Ω—ë–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã DeepSeek (—Ç–∞–π–º–∞—É—Ç 20 —Å–µ–∫), —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ –∏—â–µ—Ç.
    """
    logging.info(f"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
    search_results = {
        "es_results": [],
        "es_case_refs": [],
        "tavily_queries": [],
        "tavily_results": [],
        "tavily_case_refs": [],
        "metadata": {
            "start_time": time.time(),
            "query": query,
            "success": False,
            "error": None
        }
    }
    try:
        # 1. –ü–æ–ª—É—á–∞–µ–º –¥–≤–∞ —É—Ç–æ—á–Ω—ë–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ DeepSeek —Å —Ç–∞–π–º–∞—É—Ç–æ–º
        optimizer = QueryOptimizer()
        try:
            tavily_queries = await asyncio.wait_for(optimizer.get_two_search_queries(query), timeout=20)
            if not tavily_queries or not any(tavily_queries):
                tavily_queries = [query]
                logging.warning("‚è≥ DeepSeek –Ω–µ –≤–µ—Ä–Ω—É–ª —É—Ç–æ—á–Ω—ë–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
        except asyncio.TimeoutError:
            tavily_queries = [query]
            logging.warning("‚è≥ –¢–∞–π–º–∞—É—Ç DeepSeek (20 —Å–µ–∫). –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
        except Exception as e:
            tavily_queries = [query]
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —É—Ç–æ—á–Ω—ë–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
        search_results["tavily_queries"] = tavily_queries
        logging.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞–ø—Ä–æ—Å—ã: {tavily_queries}")

        # 2. –ü–æ–∏—Å–∫ –≤ Tavily –ø–æ –∫–∞–∂–¥–æ–º—É —É—Ç–æ—á–Ω—ë–Ω–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É
        async def search_tavily(tq: str) -> List[Dict]:
            try:
                tavily_service = TavilyService()
                results = await tavily_service.search(tq, max_results=7)
                if results:
                    logging.info(f"üìù –ü–æ–ª—É—á–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Tavily –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{tq}': {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                    seen_urls = set()
                    unique_results = []
                    for r in results:
                        url = r.get('href', '')
                        if url and url not in seen_urls:
                            seen_urls.add(url)
                            r['query'] = tq
                            r['timestamp'] = time.time()
                            unique_results.append(r)
                    return unique_results
                return []
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ Tavily –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{tq}': {str(e)}")
                return []
        tavily_tasks = [search_tavily(tq) for tq in tavily_queries]
        tavily_results = await asyncio.gather(*tavily_tasks)
        all_tavily_results = []
        seen_urls = set()
        for results in tavily_results:
            for r in results:
                url = r.get('href', '')
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    all_tavily_results.append(r)
        search_results["tavily_results"] = all_tavily_results
        search_results["tavily_results_raw"] = tavily_results
        logging.info(f"‚úÖ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(all_tavily_results)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Tavily")

        # 3. –ü–æ–∏—Å–∫ –≤ Elasticsearch –ø–æ —É—Ç–æ—á–Ω—ë–Ω–Ω—ã–º –∑–∞–ø—Ä–æ—Å–∞–º
        es_results_by_tavily = []
        if tavily_queries:
            es_results_by_tavily = await asyncio.gather(*[
                asyncio.create_task(search_law_chunks(q)) for q in tavily_queries
            ])
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –±–ª–æ–∫–∞
            all_es_results = search_law_chunks_multi(tavily_queries, size=5)
            all_texts = set(hashlib.md5(r.get("text", "").strip().encode()).hexdigest() 
                          for r in search_results["es_results"])
            for r in all_es_results:
                text = r.get("text", "").strip()
                text_hash = hashlib.md5(text.encode()).hexdigest()
                if text_hash not in all_texts:
                    search_results["es_results"].append(r)
                    all_texts.add(text_hash)
        search_results["es_results_by_tavily"] = es_results_by_tavily

        # 4. –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä–∞ –¥–µ–ª –∏ —Ä–µ–∫–≤–∏–∑–∏—Ç—ã –∏–∑ ElasticSearch (–ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º)
        es_case_refs = []
        for res in search_results["es_results"]:
            text = res.get("text", "")
            case_numbers = set()
            patterns = [
                r'\b\d{2,}-[–ê-–Ø–∞-—èA-Za-z0-9\-]+\b',
                r'‚Ññ\s*\d+[\-\w]*',
                r'–¥–µ–ª–æ\s*‚Ññ\s*\d+[\-\w]*',
                r'[–ê-–Ø]\d{2,}-\d+/\d{4}',
            ]
            for pattern in patterns:
                found = re.findall(pattern, text)
                case_numbers.update(found)
            if case_numbers:
                es_case_refs.append({
                    "case_numbers": list(case_numbers),
                    "title": res.get("title", ""),
                    "metadata": res.get("metadata", {})
                })
        search_results["es_case_refs"] = es_case_refs

        # 5. –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        search_results["metadata"].update({
            "success": True,
            "execution_time": time.time() - search_results["metadata"]["start_time"],
            "es_results_count": len(search_results["es_results"]),
            "tavily_results_count": len(all_tavily_results),
            "es_by_tavily_count": sum(len(res) for res in es_results_by_tavily)
        })
        logging.info(f"‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {search_results['metadata']['execution_time']:.2f} —Å–µ–∫—É–Ω–¥")
        return search_results
    except Exception as e:
        error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–º –ø–æ–∏—Å–∫–µ: {e}"
        logging.error(error_msg)
        search_results["metadata"]["error"] = str(e)
        search_results["metadata"]["execution_time"] = time.time() - search_results["metadata"]["start_time"]
        return search_results

async def search_tavily(query: str) -> List[Dict[str, Any]]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ —á–µ—Ä–µ–∑ Tavily API.
    """
    logging.info(f"üîç –ù–∞—á–∞–ª–æ –ø–æ–∏—Å–∫–∞ –≤ Tavily –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
    try:
        tavily_service = TavilyService()
        results = await tavily_service.search(query, max_results=5)
        
        if not results:
            logging.warning("‚ùå Tavily –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            return []
            
        logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç Tavily")
        return results
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ Tavily: {str(e)}")
        return []