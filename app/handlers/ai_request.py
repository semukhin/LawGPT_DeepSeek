"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å DeepSeek API.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ—Ç–ø—Ä–∞–≤–∫—É –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤.
"""
from typing import Dict, Optional, List, Any
from sqlalchemy.orm import Session 
import json
import asyncio
from app.handlers.parallel_search import run_parallel_search
from app.handlers.es_law_search import search_law_chunks
from app.handlers.web_search import run_multiple_searches
from app.services.deepresearch_service import DeepResearchService
from app.services.deepseek_service import DeepSeekService
from app.models import get_messages
from app.config import DEEPSEEK_API_KEY, DEEPSEEK_MODEL
from app.context_manager import ContextManager
from app.utils.logger import get_logger

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞
logger = get_logger()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤
deep_research_service = DeepResearchService()
deepseek_service = DeepSeekService()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
context_manager = ContextManager(model=DEEPSEEK_MODEL)

# –î–æ–±–∞–≤–∏—Ç—å –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
MAX_PROMPT_CHARS = 30000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –ø—Ä–æ–º—Ç–∞
MAX_SEARCH_RESULTS_CHARS = 10000  # –õ–∏–º–∏—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
MAX_ES_RESULT_CHARS = 10000  # –õ–∏–º–∏—Ç –Ω–∞ –æ–¥–∏–Ω —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏–∑ ElasticSearch
MAX_WEB_RESULT_CHARS = 3800  # –õ–∏–º–∏—Ç –Ω–∞ –æ–¥–∏–Ω –≤–µ–±-—Ä–µ–∑—É–ª—å—Ç–∞—Ç

# –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
GENERAL_SYSTEM_PROMPT = """–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ –†–§."""

RESEARCH_SYSTEM_PROMPT = """–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–∞–≤–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã, –∏—Å–ø–æ–ª—å–∑—É—è –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ –†–§, —Å—É–¥–µ–±–Ω—É—é –ø—Ä–∞–∫—Ç–∏–∫—É –∏ –ø—Ä–∞–≤–æ–≤—ã–µ –ø–æ–∑–∏—Ü–∏–∏."""

def log_function_call(function_name: str, arguments: Dict) -> None:
    """–õ–æ–≥–∏—Ä—É–µ—Ç –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏."""
    logger.info(f"üîç –§–£–ù–ö–¶–ò–Ø –í–´–ó–í–ê–ù–ê: {function_name}")
    logger.info(f"üîç –ê–†–ì–£–ú–ï–ù–¢–´: {json.dumps(arguments, ensure_ascii=False)}")

def format_chat_history(chat_history: List[Dict]) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –≤ —Å—Ç—Ä–æ–∫—É.
    
    Args:
        chat_history: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        
    Returns:
        str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞
    """
    if not chat_history:
        return ""
        
    formatted = []
    for msg in chat_history:
        formatted.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {msg.get('user_message', '')}")
        formatted.append(f"–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {msg.get('assistant_message', '')}")
    
    return "\n".join(formatted)

def build_deepseek_messages(system_prompt: str, chat_history: List[Dict], user_query: str) -> List[Dict]:
    messages = [{"role": "system", "content": system_prompt}]
    for msg in chat_history[-10:]:
        if msg["role"] in ("user", "assistant"):
            messages.append({"role": msg["role"], "content": msg["content"]})
    messages.append({"role": "user", "content": user_query})
    return messages

async def send_custom_request(
    user_query: str,
    thread_id: Optional[str] = None,
    db: Optional[Session] = None,
    document_text: str = "",
    chat_history: Optional[str] = None
) -> str:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä—è–º–æ–π –ø–æ–∏—Å–∫ –±–µ–∑ function calling.
    Args:
        user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        thread_id: ID —Ç—Ä–µ–¥–∞ —á–∞—Ç–∞
        db: –°–µ—Å—Å–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        document_text: –¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        chat_history: –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å—Ç—Ä–æ–∫–∏
    Returns:
        str: –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    """
    logger.info(f"üìù –ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_query[:100]}...")
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
        messages = None
        if chat_history:
            try:
                messages = json.loads(chat_history)
            except json.JSONDecodeError:
                logger.warning("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –∫–∞–∫ JSON")
        if not messages and thread_id and db:
            messages = await get_messages(thread_id, db)
            logger.info(f"üìú –ü–æ–ª—É—á–µ–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞: {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
        if not messages:
            messages = []
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        research_service = DeepResearchService()
        is_general = research_service.is_general_query(user_query)
        system_prompt = GENERAL_SYSTEM_PROMPT if is_general else RESEARCH_SYSTEM_PROMPT
        deepseek_messages = build_deepseek_messages(system_prompt, messages, user_query)
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Ç–æ–ª—å–∫–æ –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        search_results = None
        if not is_general:
            logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞")
            search_results = await run_parallel_search(user_query)
        else:
            logger.info("üìù –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –±–µ–∑ –ø–æ–∏—Å–∫–∞")
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, –ø–µ—Ä–µ–¥–∞–≤–∞—è –º–∞—Å—Å–∏–≤ —Å–æ–æ–±—â–µ–Ω–∏–π
        result = await research_service.research(
            query=user_query,
            chat_history=deepseek_messages,  # —Ç–µ–ø–µ—Ä—å —ç—Ç–æ –º–∞—Å—Å–∏–≤ —Å–æ–æ–±—â–µ–Ω–∏–π
            search_data=search_results,
            thread_id=thread_id,
            db=db
        )
        return result.analysis
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
        return f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"


# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ö–µ–º —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è DeepSeek API
AVAILABLE_FUNCTIONS = [
    {
        "name": "search_law_chunks",
        "description": "–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É. –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –æ –∑–∞–∫–æ–Ω–∞—Ö, –ø—Ä–∞–≤–æ–≤—ã—Ö –Ω–æ—Ä–º–∞—Ö, –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–º –∫–æ–¥–µ–∫—Å–µ, –∏ –¥—Ä—É–≥–∏—Ö –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã—Ö –∞–∫—Ç–∞—Ö.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "–¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ. –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –Ω–æ–º–µ—Ä–∞ —Å—Ç–∞—Ç–µ–π, –µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã."
                }
            },
            "required": ["query"]
        }
    },
    {
        "name": "search_web",
        "description": "–ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É. –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—É–¥–µ–±–Ω–æ–π –ø—Ä–∞–∫—Ç–∫–∏–∏, –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —Å—Ç–∞—Ç–µ–π, –∏ –æ–±–∑–æ—Ä–æ–≤.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "–¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ. –ó–∞–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω —Ç–∞–∫, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–º–µ."
                }
            },
            "required": ["query"]
        }
    },
    {
        "name": "deep_research",
        "description": "–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É. –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∞–≤–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "–¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è. –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –ø—Ä–æ–±–ª–µ–º—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."
                }
            },
            "required": ["query"]
        }
    }
]


async def handle_function_call(function_name: str, arguments: Dict, thread_id: Optional[str] = None, db: Optional[Session] = None) -> Dict[str, Any]:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º.
    
    Args:
        function_name: –ò–º—è –≤—ã–∑—ã–≤–∞–µ–º–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
        arguments: –ê—Ä–≥—É–º–µ–Ω—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏
        thread_id: ID —Ç—Ä–µ–¥–∞ —á–∞—Ç–∞
        db: –°–µ—Å—Å–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        
    Returns:
        Dict[str, Any]: –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏
    """
    query = arguments.get("query", "")

    # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    log_function_call(function_name, arguments)

    if function_name == "search_law_chunks":
        try:
            logger.info("üîç –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –≤ Elasticsearch –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '%s'", query)
            es_results = search_law_chunks(query)
            if es_results:
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(es_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –≤ Elasticsearch")
                for i, chunk in enumerate(es_results[:2]):  # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 2 —á–∞–Ω–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                    logger.info(f"üìÑ –ß–∞–Ω–∫ {i+1}: {chunk[:100]}...")

                # –°–æ–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏ –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
                combined_text = "\n\n".join(es_results)

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º DeepResearch –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞
                result = await deep_research_service.research(
                    query=combined_text
                )
                
                return {
                    "found": True,
                    "chunks_count": len(es_results),
                    "deep_research_results": result.to_dict()
                }
            else:
                return {"found": False, "error": "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."}
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ: {str(e)}")
            return {"found": False, "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ: {str(e)}"}

    elif function_name == "search_web":
        try:
            logger.info("üîç –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤–µ–±-–ø–æ–∏—Å–∫–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '%s'", query)
            logs = []

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–≥–æ
            search_results = await run_multiple_searches(query, logs)

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø–æ–∏—Å–∫–∞
            all_results = []
            for search_type, results in search_results.items():
                all_results.extend(results)

            if all_results:
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(all_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü")

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                extracted_texts = []
                for result in all_results:
                    if result.is_successful():
                        extracted_texts.append({
                            "url": result.url,
                            "title": result.title,
                            "text": result.text[:2000]  # –ë–µ—Ä–µ–º –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                        })

                combined_text = "\n\n".join([
                    f"–ò—Å—Ç–æ—á–Ω–∏–∫: {item['url']}\n–ó–∞–≥–æ–ª–æ–≤–æ–∫: {item['title']}\n{item['text']}"
                    for item in extracted_texts
                ])

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º DeepResearch –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                result = await deep_research_service.research(
                    query=combined_text
                )
                
                return {
                    "found": True, 
                    "sources_count": len(extracted_texts),
                    "sources": [{"url": item["url"], "title": item["title"]} for item in extracted_texts[:5]],
                    "deep_research_results": result.to_dict()
                }
            else:
                return {"found": False, "error": "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–µ–±-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."}
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–µ–±-–ø–æ–∏—Å–∫–µ: {str(e)}")
            return {"found": False, "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–µ–±-–ø–æ–∏—Å–∫–µ: {str(e)}"}

    elif function_name == "deep_research":
        try:
            logger.info("üîç –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '%s'", query)

            # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            logs = []
            additional_context = []

            # 1. –ü–æ–∏—Å–∫ –≤ Elasticsearch
            try:
                es_results = search_law_chunks(query)
                if es_results:
                    additional_context.append({
                        "type": "legislation",
                        "found": True,
                        "data": es_results[:10]  # –ë–µ—Ä–µ–º –¥–æ 10 –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    })
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ Elasticsearch: {str(e)}")

            # 2. –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
            try:
                web_results = await run_multiple_searches(query, logs)
                all_web_results = []
                for search_type, results in web_results.items():
                    all_web_results.extend(results)

                if all_web_results:
                    extracted_texts = []
                    for result in all_web_results:
                        if result.is_successful():
                            extracted_texts.append({
                                "url": result.url,
                                "title": result.title,
                                "text": result.text[:2000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                            })

                    if extracted_texts:
                        additional_context.append({
                            "type": "web",
                            "found": True,
                            "data": extracted_texts[:3]  # –ë–µ—Ä–µ–º –¥–æ 3 –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        })
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞: {str(e)}")

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –≤—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            result = await deep_research_service.research(
                query=query,
                additional_context=additional_context
            )
            
            return {
                "found": True,
                "deep_research_results": result.to_dict()
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–ª—É–±–æ–∫–æ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏: {str(e)}")
            return {"found": False, "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–ª—É–±–æ–∫–æ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏: {str(e)}"}

    return {"found": False, "error": f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: {function_name}"}