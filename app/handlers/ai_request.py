"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å DeepSeek API.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ—Ç–ø—Ä–∞–≤–∫—É –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤.
"""
from typing import Dict, Optional, List, Any, Union
from sqlalchemy.orm import Session 
import logging
import json
import asyncio
from app.handlers.parallel_search import run_parallel_search
from app.utils import measure_time
from app.handlers.es_law_search import search_law_chunks
from app.handlers.web_search import google_search, search_and_scrape, run_multiple_searches
from app.services.deepresearch_service import DeepResearchService, ResearchResult
from app.services.deepseek_service import DeepSeekService
from app.models import Message, Thread
from app.config import DEEPSEEK_API_KEY, DEEPSEEK_MODEL
from app.context_manager import ContextManager
from app.utils.chat_utils import get_messages

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤
deep_research_service = DeepResearchService()
deepseek_service = DeepSeekService(
    api_key=DEEPSEEK_API_KEY, 
    model=DEEPSEEK_MODEL,
    temperature=0.7,    
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
context_manager = ContextManager(model=DEEPSEEK_MODEL)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# –î–æ–±–∞–≤–∏—Ç—å –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
MAX_PROMPT_CHARS = 30000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –ø—Ä–æ–º—Ç–∞
MAX_SEARCH_RESULTS_CHARS = 10000  # –õ–∏–º–∏—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
MAX_ES_RESULT_CHARS = 10000  # –õ–∏–º–∏—Ç –Ω–∞ –æ–¥–∏–Ω —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏–∑ ElasticSearch
MAX_WEB_RESULT_CHARS = 3800  # –õ–∏–º–∏—Ç –Ω–∞ –æ–¥–∏–Ω –≤–µ–±-—Ä–µ–∑—É–ª—å—Ç–∞—Ç

def log_function_call(function_name: str, arguments: Dict) -> None:
    """–õ–æ–≥–∏—Ä—É–µ—Ç –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏."""
    logging.info(f"üîç –§–£–ù–ö–¶–ò–Ø –í–´–ó–í–ê–ù–ê: {function_name}")
    logging.info(f"üîç –ê–†–ì–£–ú–ï–ù–¢–´: {json.dumps(arguments, ensure_ascii=False)}")

@measure_time
async def send_custom_request(user_query: str, thread_id: Optional[str] = None, db: Optional[Session] = None, document_text: str = "") -> str:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä—è–º–æ–π –ø–æ–∏—Å–∫ –±–µ–∑ function calling.
    """
    logging.info(f"üìù –ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_query[:100]}...")

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π, –µ—Å–ª–∏ –µ—Å—Ç—å thread_id
        chat_history = []
        if thread_id and db:
            chat_history = await get_messages(thread_id, db)
            logging.info(f"üìú –ü–æ–ª—É—á–µ–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞: {len(chat_history)} —Å–æ–æ–±—â–µ–Ω–∏–π")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –∏—Å—Ç–æ—Ä–∏–µ–π
        prepared_context = context_manager.prepare_context(chat_history)
        logging.info(f"üìú –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {len(prepared_context)} —Å–æ–æ–±—â–µ–Ω–∏–π")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å –æ–±—â–∏–º –≤–æ–ø—Ä–æ—Å–æ–º (–Ω–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º)
        is_general = deep_research_service.is_general_query(query=user_query)
        
        logging.info(f"üîé –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ is_general_query: {'–æ–±—â–∏–π –∑–∞–ø—Ä–æ—Å' if is_general else '—é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å'}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        enhanced_query = f"–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:\n{user_query}\n\n"
        
        # –î–ª—è –æ–±—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫
        if not is_general:
            logging.info("üîç –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫
            search_results = await run_parallel_search(user_query)
            
            if search_results and not search_results.get("error"):
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ –∑–∞–ø—Ä–æ—Å
                if "combined_context" in search_results:
                    enhanced_query += "–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê:\n" + search_results["combined_context"]
                else:
                    enhanced_query += "–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê:\n–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."
            else:
                enhanced_query += "–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê:\n–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –≤ –∑–∞–ø—Ä–æ—Å
        if prepared_context:
            enhanced_query += "\n–ò–°–¢–û–†–ò–Ø –ß–ê–¢–ê:\n"
            for msg in prepared_context:
                role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg["role"] == "user" else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
                enhanced_query += f"{role}: {msg['content']}\n"
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç DeepSeek API, –ø–µ—Ä–µ–¥–∞–≤–∞—è —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        response = await deep_research_service.research(enhanced_query, is_general=is_general)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if isinstance(response, ResearchResult):
            assistant_response = response.analysis
        elif isinstance(response, dict) and 'choices' in response and len(response['choices']) > 0:
            assistant_response = response['choices'][0]['message']['content']
        else:
            assistant_response = str(response)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ë–î
        if thread_id and db:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_message = Message(
                thread_id=thread_id,
                role="user",
                content=user_query
            )
            db.add(user_message)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            assistant_message = Message(
                thread_id=thread_id,
                role="assistant",
                content=assistant_response
            )
            db.add(assistant_message)
            db.commit()
        
        return assistant_response
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
        return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"


# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ö–µ–º —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è DeepSeek API
AVAILABLE_FUNCTIONS = [
    {
        "name": "search_law_chunks",
        "description": "–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É. –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –æ –∑–∞–∫–æ–Ω–∞—Ö, –ø—Ä–∞–≤–æ–≤—ã—Ö –Ω–æ—Ä–º–∞—Ö, –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–º –∫–æ–¥–µ–∫—Å–µ, –∏ –¥—Ä—É–≥–∏—Ö –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã—Ö –∞–∫—Ç–∞—Ö.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "–¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ. –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –Ω–æ–º–µ—Ä–∞ —Å—Ç–∞—Ç–µ–π, –µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã."
                }
            },
            "required": ["query"]
        }
    },
    {
        "name": "search_web",
        "description": "–ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É. –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—É–¥–µ–±–Ω–æ–π –ø—Ä–∞–∫—Ç–∫–∏–∏, –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —Å—Ç–∞—Ç–µ–π, –∏ –æ–±–∑–æ—Ä–æ–≤.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "–¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ. –ó–∞–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω —Ç–∞–∫, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–º–µ."
                }
            },
            "required": ["query"]
        }
    },
    {
        "name": "deep_research",
        "description": "–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É. –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∞–≤–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "–¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è. –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –ø—Ä–æ–±–ª–µ–º—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."
                }
            },
            "required": ["query"]
        }
    }
]


@measure_time
async def handle_function_call(function_name: str, arguments: Dict, thread_id: Optional[str] = None, db: Optional[Session] = None) -> Dict:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º."""
    query = arguments.get("query", "")

    # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    log_function_call(function_name, arguments)

    if function_name == "search_law_chunks":
        try:
            logging.info("üîç –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –≤ Elasticsearch –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '%s'", query)
            es_results = search_law_chunks(query)
            if es_results:
                logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(es_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –≤ Elasticsearch")
                for i, chunk in enumerate(es_results[:2]):  # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 2 —á–∞–Ω–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                    logging.info(f"üìÑ –ß–∞–Ω–∫ {i+1}: {chunk[:100]}...")

                # –°–æ–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏ –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
                combined_text = "\n\n".join(es_results)

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º DeepResearch –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞
                deep_results = await deep_research_service.research(
                    query=combined_text, 
                    thread_id=thread_id,  # –ü–µ—Ä–µ–¥–∞–µ–º thread_id
                    message_id=None, 
                    user_id=None, 
                    db=db  # –ü–µ—Ä–µ–¥–∞–µ–º db
                )

                return {
                    "found": True,
                    "chunks_count": len(es_results),
                    "deep_research_results": deep_results.to_dict()
                }

            logging.info("‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
            return {"found": False, "error": "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."}
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ: {str(e)}")
            return {"found": False, "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ: {str(e)}"}


    elif function_name == "search_web":
        try:
            logging.info("üîç –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤–µ–±-–ø–æ–∏—Å–∫–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '%s'", query)
            logs = []

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–≥–æ
            search_results = await run_multiple_searches(query, logs)

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø–æ–∏—Å–∫–∞
            all_results = []
            for search_type, results in search_results.items():
                all_results.extend(results)

            if all_results:
                logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(all_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü")

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                extracted_texts = []
                for result in all_results:
                    if result.is_successful():
                        extracted_texts.append({
                            "url": result.url,
                            "title": result.title,
                            "text": result.text[:2000]  # –ë–µ—Ä–µ–º –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                        })

                combined_text = "\n\n".join([
                    f"–ò—Å—Ç–æ—á–Ω–∏–∫: {item['url']}\n–ó–∞–≥–æ–ª–æ–≤–æ–∫: {item['title']}\n{item['text']}"
                    for item in extracted_texts
                ])

                user_id = None
                message_id = None
                if thread_id and db:
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                        user_message = db.query(Message).filter(
                            Message.thread_id == thread_id,
                            Message.role == "user"
                        ).order_by(Message.created_at.desc()).limit(10).first()

                        if user_message:
                            message_id = user_message.id

                        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ —Å–≤—è–∑—å —Ç—Ä–µ–¥–∞
                        thread = db.query(Thread).filter(Thread.id == thread_id).first()
                        if thread:
                            user_id = thread.user_id
                    except Exception as e:
                        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º DeepResearch –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                deep_results = await deep_research_service.research(combined_text)

                return {
                    "found": True, 
                    "sources_count": len(extracted_texts),
                    "sources": [{"url": item["url"], "title": item["title"]} for item in extracted_texts[:5]],
                    "deep_research_results": deep_results.to_dict()
                }

            logging.info("‚ùå –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–µ–±-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
            return {"found": False, "error": "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–µ–±-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."}
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–µ–±-–ø–æ–∏—Å–∫–µ: {str(e)}")
            return {"found": False, "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–µ–±-–ø–æ–∏—Å–∫–µ: {str(e)}"}


    elif function_name == "deep_research":
        try:
            logging.info("üîç –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '%s'", query)

            # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            logs = []
            additional_context = []

            # 1. –ü–æ–∏—Å–∫ –≤ Elasticsearch
            try:
                es_results = search_law_chunks(query)
                if es_results:
                    additional_context.append({
                        "type": "legislation",
                        "found": True,
                        "data": es_results[:10]  # –ë–µ—Ä–µ–º –¥–æ 10 –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    })
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ Elasticsearch: {str(e)}")

            # 2. –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
            try:
                web_results = await run_multiple_searches(query, logs)
                all_web_results = []
                for search_type, results in web_results.items():
                    all_web_results.extend(results)

                if all_web_results:
                    extracted_texts = []
                    for result in all_web_results:
                        if result.is_successful():
                            extracted_texts.append({
                                "url": result.url,
                                "title": result.title,
                                "text": result.text[:2000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                            })

                    if extracted_texts:
                        additional_context.append({
                            "type": "web",
                            "found": True,
                            "data": extracted_texts[:3]  # –ë–µ—Ä–µ–º –¥–æ 3 –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        })
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞: {str(e)}")

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –≤—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            deep_results = await deep_research_service.research(query, additional_context)

            return {
                "found": True,
                "deep_research_results": deep_results.to_dict()
            }
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–ª—É–±–æ–∫–æ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏: {str(e)}")
            return {"found": False, "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–ª—É–±–æ–∫–æ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏: {str(e)}"}

    return {"found": False, "error": f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: {function_name}"}