# app/handlers/es_law_search.py

import logging
from typing import List
from elasticsearch import Elasticsearch

# –ó–∞–¥–∞–π—Ç–µ —Å–≤–æ–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
ES_HOST = "http://localhost:9200"
ES_USER = "elastic"
ES_PASS = "GIkb8BKzkXK7i2blnG2O"
ES_INDEX_NAME = "ruslawod_index"


def search_law_chunks(query: str, top_n: int = 15) -> List[str]:
    """
    –ò—â–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –≤ Elasticsearch.
    """
    try:
        # –°–æ–∑–¥–∞—ë–º –∫–ª–∏–µ–Ω—Ç —Å –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ —Å–µ—Å—Å–∏–∏
        es = Elasticsearch(
            [ES_HOST],
            basic_auth=(ES_USER, ES_PASS),
            retry_on_timeout=True,
            max_retries=3,
            request_timeout=30
        )

        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        body = {
            "size": top_n,
            "query": {
                "bool": {
                    "should": [
                        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –≤—ã—Å–æ–∫–∏–º –≤–µ—Å–æ–º
                        {
                            "match_phrase": {
                                "text_chunk": {
                                    "query": query,
                                    "boost": 5
                                }
                            }
                        },
                        # –ú–Ω–æ–≥–æ–ø–æ–ª–µ–≤–æ–π –ø–æ–∏—Å–∫
                        {
                            "multi_match": {
                                "query": query,
                                "fields": ["text_chunk^3", "title^2", "document_number", "document_type"],
                                "type": "best_fields",
                                "fuzziness": "AUTO"
                            }
                        }
                    ],
                    "minimum_should_match": 1
                }
            },
            "highlight": {
                "fields": {
                    "text_chunk": {
                        "pre_tags": ["<b>"],
                        "post_tags": ["</b>"],
                        "fragment_size": 300,
                        "number_of_fragments": 3
                    }
                }
            }
        }

        response = es.search(index=ES_INDEX_NAME, body=body)
        hits = response["hits"]["hits"]

        results = []
        for hit in hits:
            source = hit["_source"]
            chunk_text = source["text_chunk"]
            document_title = source.get("title", "")
            document_number = source.get("document_number", "")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥—Å–≤–µ—Ç–∫—É, –µ—Å–ª–∏ –µ—Å—Ç—å
            highlights = hit.get("highlight", {}).get("text_chunk", [])
            if highlights:
                highlight_text = "...\n".join(highlights)
                results.append(f"–î–æ–∫—É–º–µ–Ω—Ç: {document_title} ({document_number})\n–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã:\n{highlight_text}\n\n–ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n{chunk_text[:1000]}...")
            else:
                results.append(f"–î–æ–∫—É–º–µ–Ω—Ç: {document_title} ({document_number})\n{chunk_text[:1500]}...")

        logging.info(f"üîç [ES] –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.")
        return results

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ Elasticsearch: {e}")
        return []