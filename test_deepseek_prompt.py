import sys
import os
import json
import asyncio
import logging
from typing import Dict, List, Optional
from datetime import datetime
import codecs
import locale

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞–ª–∞
os.environ["PYTHONIOENCODING"] = "utf-8"
locale.setlocale(locale.LC_ALL, "")

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.deepresearch_service import DeepResearchService
from app.handlers.web_search import search_and_scrape
from app.handlers.es_law_search import search_law_chunks
from app.utils import ensure_correct_encoding, validate_messages, validate_context

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
log_dir = 'logs'
if not os.path.exists(log_dir):
    os.makedirs(log_dir)

# –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –ª–æ–≥–∞ —Å —Ç–µ–∫—É—â–µ–π –¥–∞—Ç–æ–π
log_filename = os.path.join(log_dir, f'deepseek_prompt_test_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')

# –°–æ–∑–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä –¥–ª—è –ª–æ–≥–æ–≤
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

# –°–æ–∑–¥–∞–µ–º –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Ñ–∞–π–ª–∞
file_handler = logging.FileHandler(log_filename, encoding='utf-8', mode='w')
file_handler.setFormatter(formatter)
file_handler.setLevel(logging.INFO)

# –°–æ–∑–¥–∞–µ–º –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π UTF-8
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setFormatter(formatter)
console_handler.setLevel(logging.INFO)

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π –ª–æ–≥–≥–µ—Ä
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
for handler in logger.handlers[:]:
    logger.removeHandler(handler)

# –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
logger.addHandler(console_handler)
logger.addHandler(file_handler)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
def save_result_to_file(result_dict: dict, prefix: str = "result"):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_filename = os.path.join(log_dir, f'{prefix}_{timestamp}.json')
    with open(result_filename, 'w', encoding='utf-8') as f:
        json.dump(ensure_correct_encoding(result_dict), f, ensure_ascii=False, indent=2)
    logging.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {result_filename}")

class PromptAnalyzer:
    def __init__(self):
        self.research_service = DeepResearchService()
        self.logs = []

    async def analyze_prompt_formation(self, query: str):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
        
        logging.info("\nüîç –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞")
        logging.info(f"–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n{query}")
        
        # 1. –ü–æ–∏—Å–∫ –≤ ElasticSearch
        logging.info("\n=== –ü–æ–∏—Å–∫ –≤ ElasticSearch ===")
        es_results = search_law_chunks(query)
        es_content = ""
        if es_results:
            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            logging.info("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–∑ ElasticSearch:")
            if es_results and len(es_results) > 0:
                logging.info(f"–¢–∏–ø –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(es_results[0])}")
                if isinstance(es_results[0], dict):
                    logging.info(f"–ö–ª—é—á–∏ –≤ —Å–ª–æ–≤–∞—Ä–µ: {es_results[0].keys()}")
                logging.info(f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {es_results[0]}")

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
            formatted_results = []
            for i, result in enumerate(es_results, 1):
                try:
                    # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç - —Å–ª–æ–≤–∞—Ä—å, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç
                    if isinstance(result, dict):
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–ª—é—á–∏
                        text = (result.get('text') or 
                               result.get('content') or 
                               result.get('source_text') or 
                               result.get('form_text') or 
                               str(result))
                    else:
                        text = str(result)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
                    fixed_text = ensure_correct_encoding(text)
                    formatted_results.append(f"–ò—Å—Ç–æ—á–Ω–∏–∫ {i}:\n{fixed_text}")
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ {i}: {str(e)}")
                    logging.error(f"–ü—Ä–æ–±–ª–µ–º–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
            
            es_content = "\n\n".join(formatted_results)
            logging.info(f"–ù–∞–π–¥–µ–Ω–æ {len(es_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ ElasticSearch")
            logging.info(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ElasticSearch: {len(es_content)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # 2. –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
        logging.info("\n=== –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ ===")
        web_results = await search_and_scrape(query, self.logs)
        web_content = ""
        if web_results:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –≤–µ–±-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            web_content = "\n\n".join([
                f"–ò—Å—Ç–æ—á–Ω–∏–∫ {i+1} ({result['url']}):\n{ensure_correct_encoding(result['text'])}"
                for i, result in enumerate(web_results)
            ])
            logging.info(f"–ù–∞–π–¥–µ–Ω–æ {len(web_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ")
            logging.info(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞: {len(web_content)} —Å–∏–º–≤–æ–ª–æ–≤")

        # 3. –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        additional_context = []
        if es_content:
            additional_context.append({
                "source": "elasticsearch",
                "data": es_content
            })
        if web_content:
            additional_context.append({
                "source": "web",
                "data": web_content
            })

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        additional_context = validate_context(additional_context)

        # 4. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ DeepSeek –∏ –ø–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ–º–ø—Ç
        logging.info("\n=== –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ DeepSeek ===")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ post
        original_post = self.research_service.deepseek_service.chat_completion
        
        # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞
        async def intercepted_chat_completion(messages, **kwargs):
            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö
            logging.info("\n=== –û—Ç–ª–∞–¥–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π ===")
            logging.info(f"–¢–∏–ø messages: {type(messages)}")
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            prompts_dir = 'prompts'
            if not os.path.exists(prompts_dir):
                os.makedirs(prompts_dir)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            for i, msg in enumerate(messages):
                msg_file = os.path.join(prompts_dir, f'message_{timestamp}_{i+1}.txt')
                try:
                    with open(msg_file, 'w', encoding='utf-8') as f:
                        f.write(f"Role: {msg.get('role', 'unknown')}\n")
                        f.write(f"Content:\n{msg.get('content', '')}")
                    logging.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ {i+1} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Ñ–∞–π–ª: {msg_file}")
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è {i+1}: {str(e)}")

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
            formatted_messages = []
            for msg in messages:
                try:
                    if isinstance(msg, dict):
                        role = str(msg.get('role', 'unknown'))
                        content = msg.get('content', '')
                        if not isinstance(content, str):
                            content = str(content)
                        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
                        content = ensure_correct_encoding(content)
                    else:
                        role = 'unknown'
                        content = ensure_correct_encoding(str(msg))
                    
                    formatted_messages.append({
                        "role": role,
                        "content": content
                    })
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {str(e)}")
                    logging.error(f"–ü—Ä–æ–±–ª–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {msg}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤ JSON
            prompt_file = os.path.join(prompts_dir, f"deepseek_prompt_{timestamp}.json")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            model = kwargs.get('model', self.research_service.deepseek_service.model)
            temperature = kwargs.get('temperature', self.research_service.deepseek_service.temperature)
            max_tokens = kwargs.get('max_tokens', self.research_service.deepseek_service.max_tokens)
            
            try:
                prompt_data = {
                    "timestamp": timestamp,
                    "query": query,
                    "messages": formatted_messages,
                    "parameters": {
                        "model": model,
                        "temperature": temperature,
                        "max_tokens": max_tokens
                    },
                    "context_info": {
                        "es_results_count": len(es_results) if es_results else 0,
                        "web_results_count": len(web_results) if web_results else 0,
                        "total_context_size": sum(len(msg.get('content', '')) for msg in formatted_messages)
                    }
                }
                
                with open(prompt_file, 'w', encoding='utf-8') as f:
                    json.dump(prompt_data, f, ensure_ascii=False, indent=2)
                logging.info(f"üíæ –ü–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {prompt_file}")
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã —Å–æ–æ–±—â–µ–Ω–∏–π
                logging.info("\n=== –†–∞–∑–º–µ—Ä—ã —Å–æ–æ–±—â–µ–Ω–∏–π ===")
                for i, msg in enumerate(formatted_messages):
                    logging.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ {i+1} ({msg['role']}): {len(msg['content'])} —Å–∏–º–≤–æ–ª–æ–≤")
                logging.info(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞: {prompt_data['context_info']['total_context_size']} —Å–∏–º–≤–æ–ª–æ–≤")
                
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–æ–º–ø—Ç–∞: {str(e)}")
            
            # –í—ã–∑—ã–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ —Å –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
            try:
                return await original_post(formatted_messages, **kwargs)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ original_post: {str(e)}")
                logging.error(f"formatted_messages: {formatted_messages}")
                raise

        # –ü–æ–¥–º–µ–Ω—è–µ–º –º–µ—Ç–æ–¥
        self.research_service.deepseek_service.chat_completion = intercepted_chat_completion

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
        result = await self.research_service.research(
            query=query,
            additional_context=additional_context
        )

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        logging.info("\n=== –ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞ DeepSeek ===")
        
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ—Ç–≤–µ—Ç–µ
            if isinstance(result.analysis, str):
                decoded_analysis = ensure_correct_encoding(result.analysis)
                result.analysis = decoded_analysis
                
                logging.info(f"–î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(decoded_analysis)} —Å–∏–º–≤–æ–ª–æ–≤")
                logging.info(f"\n–ù–∞—á–∞–ª–æ –æ—Ç–≤–µ—Ç–∞:\n{decoded_analysis[:500]}...\n")
                logging.info(f"\n–ö–æ–Ω–µ—Ü –æ—Ç–≤–µ—Ç–∞:\n...{decoded_analysis[-500:]}")
            else:
                logging.warning(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø –æ—Ç–≤–µ—Ç–∞: {type(result.analysis)}")
                
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}")
            logging.info(f"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {result.analysis}")

        return result

async def main():
    analyzer = PromptAnalyzer()
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    test_query = """
    –ü–æ–¥–≥–æ—Ç–æ–≤—å –ø—Ä–∞–≤–æ–≤–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ –æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏—è –¥–æ–≥–æ–≤–æ—Ä–∞ –ø–æ–¥—Ä—è–¥–∞ 
    –ø–æ —Å—Ç–∞—Ç—å–µ 715 –ì–ö –†–§ –≤ —Å–≤—è–∑–∏ —Å –Ω–∞—Ä—É—à–µ–Ω–∏–µ–º –ø–æ–¥—Ä—è–¥—á–∏–∫–æ–º —Å—Ä–æ–∫–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç. 
    –ö–∞–∫–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –Ω—É–∂–Ω—ã? –ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ñ–æ—Ä–º–∏—Ç—å —Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ?
    """
    
    logging.info("\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞ DeepSeek")
    
    try:
        result = await analyzer.analyze_prompt_formation(test_query)
        logging.info("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
        save_result_to_file({
            "query": test_query,
            "analysis": result.analysis,
            "timestamp": result.timestamp
        })
        
    except Exception as e:
        logging.error(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {str(e)}")

if __name__ == "__main__":
    asyncio.run(main()) 